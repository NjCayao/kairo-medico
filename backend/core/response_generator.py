"""
Response Generator - Generador Inteligente de Respuestas
Sistema de 3 capas: BD â†’ GPT â†’ Fallback
Aprende automÃ¡ticamente
"""

import sys
import os
from typing import Dict, Optional
import requests
import json
from datetime import datetime

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, BASE_DIR)
sys.path.insert(0, os.path.join(BASE_DIR, 'backend'))

from backend.core.ia_config_manager import IAConfigManager
from backend.database.db_manager import DatabaseManager

class ResponseGenerator:
    """
    Generador Inteligente de Respuestas
    
    Proceso:
    1. Buscar respuesta aprendida en BD
    2. Si no existe, consultar GPT
    3. Guardar nueva respuesta (aprender)
    4. Si GPT falla, usar fallback
    """
    
    def __init__(self):
        """Inicializar generador"""
        
        self.ia_config = IAConfigManager()
        self.db = DatabaseManager()
        
        # Crear tabla de respuestas aprendidas si no existe
        self._crear_tabla_respuestas()
        
        print("ğŸ’¬ Response Generator inicializado")
    
    def _crear_tabla_respuestas(self):
        """Crear tabla para almacenar respuestas aprendidas"""
        
        query = """
        CREATE TABLE IF NOT EXISTS respuestas_aprendidas (
            id INT PRIMARY KEY AUTO_INCREMENT,
            patron_mensaje VARCHAR(500),
            intencion VARCHAR(50),
            contexto_previo TEXT,
            respuesta_generada TEXT,
            origen ENUM('gpt', 'manual', 'editado') DEFAULT 'gpt',
            veces_usado INT DEFAULT 0,
            calificacion_promedio DECIMAL(3,2) DEFAULT 0,
            fecha_aprendido DATETIME DEFAULT CURRENT_TIMESTAMP,
            ultima_vez_usado DATETIME,
            activo BOOLEAN DEFAULT TRUE,
            INDEX idx_patron (patron_mensaje),
            INDEX idx_intencion (intencion),
            INDEX idx_activo (activo)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        """
        
        try:
            self.db.ejecutar_query(query)
            print("   âœ… Tabla respuestas_aprendidas verificada")
        except Exception as e:
            print(f"   âš ï¸ Error creando tabla: {e}")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # GENERACIÃ“N PRINCIPAL
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def generar_respuesta(self, 
                         mensaje: str,
                         intencion: str,
                         contexto: str,
                         system_prompt: str,
                         usar_aprendizaje: bool = True) -> Dict:
        """
        Generar respuesta inteligente
        
        Args:
            mensaje: Mensaje del usuario
            intencion: IntenciÃ³n detectada
            contexto: Contexto de la conversaciÃ³n
            system_prompt: Prompt del sistema para GPT
            usar_aprendizaje: Si debe buscar/guardar en BD
            
        Returns:
            Dict con respuesta, origen, confianza
        """
        
        # CAPA 1: Buscar respuesta aprendida
        if usar_aprendizaje:
            respuesta_aprendida = self._buscar_respuesta_aprendida(
                mensaje, 
                intencion, 
                contexto
            )
            
            if respuesta_aprendida:
                self._marcar_uso(respuesta_aprendida['id'])
                
                return {
                    'respuesta': respuesta_aprendida['respuesta'],
                    'origen': 'bd_aprendida',
                    'confianza': 0.9,
                    'id_respuesta': respuesta_aprendida['id'],
                    'veces_usado': respuesta_aprendida['veces_usado'] + 1
                }
        
        # CAPA 2: Consultar GPT
        if self.ia_config.esta_activo():
            respuesta_gpt = self._generar_con_gpt(
                mensaje,
                contexto,
                system_prompt
            )
            
            if respuesta_gpt:
                # Guardar respuesta para aprender
                if usar_aprendizaje:
                    self._guardar_respuesta_aprendida(
                        mensaje,
                        intencion,
                        contexto,
                        respuesta_gpt
                    )
                
                return {
                    'respuesta': respuesta_gpt,
                    'origen': 'gpt',
                    'confianza': 0.85,
                    'guardado': usar_aprendizaje
                }
        
        # CAPA 3: Fallback genÃ©rico
        respuesta_fallback = self._generar_fallback(mensaje, intencion)
        
        return {
            'respuesta': respuesta_fallback,
            'origen': 'fallback',
            'confianza': 0.5
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # BÃšSQUEDA EN BD
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _buscar_respuesta_aprendida(self, 
                                    mensaje: str, 
                                    intencion: str,
                                    contexto: str) -> Optional[Dict]:
        """
        Buscar respuesta similar en BD
        Usa similitud de texto
        """
        
        # Normalizar mensaje para bÃºsqueda
        patron = self._normalizar_patron(mensaje)
        
        query = """
        SELECT id, respuesta_generada, veces_usado, calificacion_promedio
        FROM respuestas_aprendidas
        WHERE activo = TRUE
          AND intencion = %s
          AND (
              patron_mensaje LIKE %s
              OR patron_mensaje = %s
          )
        ORDER BY veces_usado DESC, calificacion_promedio DESC
        LIMIT 1
        """
        
        resultado = self.db.ejecutar_query(
            query,
            (intencion, f"%{patron}%", patron)
        )
        
        if resultado:
            print(f"   âœ… Respuesta aprendida encontrada (usada {resultado[0]['veces_usado']} veces)")
            return {
                'id': resultado[0]['id'],
                'respuesta': resultado[0]['respuesta_generada'],
                'veces_usado': resultado[0]['veces_usado']
            }
        
        return None
    
    def _normalizar_patron(self, mensaje: str) -> str:
        """Normalizar mensaje para bÃºsqueda"""
        
        from unidecode import unidecode
        
        # MinÃºsculas
        patron = mensaje.lower().strip()
        
        # Quitar acentos
        patron = unidecode(patron)
        
        # Quitar palabras comunes
        palabras_comunes = ['el', 'la', 'los', 'las', 'un', 'una', 'de', 'del', 'a']
        palabras = patron.split()
        palabras = [p for p in palabras if p not in palabras_comunes]
        
        return ' '.join(palabras)
    
    def _marcar_uso(self, id_respuesta: int):
        """Marcar que una respuesta aprendida fue usada"""
        
        query = """
        UPDATE respuestas_aprendidas
        SET veces_usado = veces_usado + 1,
            ultima_vez_usado = NOW()
        WHERE id = %s
        """
        
        self.db.ejecutar_query(query, (id_respuesta,))
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # GENERACIÃ“N CON GPT
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _generar_con_gpt(self,
                        mensaje: str,
                        contexto: str,
                        system_prompt: str) -> Optional[str]:
        """Generar respuesta usando GPT"""
        
        try:
            config = self.ia_config.obtener_config()
            
            # Construir prompt completo
            prompt_usuario = f"""CONTEXTO DE LA CONVERSACIÃ“N:
{contexto}

MENSAJE DEL PACIENTE:
"{mensaje}"

INSTRUCCIONES:
- Responde de forma natural y conversacional
- MÃ¡ximo 3 lÃ­neas
- Usa el nombre del paciente si estÃ¡ disponible
- SÃ© empÃ¡tico y profesional
- NO uses markdown ni formato especial

RESPUESTA:"""
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={
                    'Authorization': f"Bearer {config['api_key']}",
                    'Content-Type': 'application/json'
                },
                json={
                    'model': config['modelo'],
                    'messages': [
                        {'role': 'system', 'content': system_prompt},
                        {'role': 'user', 'content': prompt_usuario}
                    ],
                    'temperature': 0.8,
                    'max_tokens': 200
                },
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                respuesta = data['choices'][0]['message']['content'].strip()
                
                # Limpiar formato
                respuesta = respuesta.replace('**', '').replace('*', '')
                respuesta = respuesta.replace('#', '').replace('```', '')
                
                # Incrementar contador
                self.ia_config.incrementar_consulta(0.003)
                
                print(f"   âœ… Respuesta GPT generada")
                
                return respuesta
            else:
                print(f"   âŒ Error GPT: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"   âŒ Error consultando GPT: {e}")
            return None
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # GUARDAR RESPUESTA (APRENDIZAJE)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _guardar_respuesta_aprendida(self,
                                     mensaje: str,
                                     intencion: str,
                                     contexto: str,
                                     respuesta: str):
        """Guardar respuesta en BD para aprendizaje futuro"""
        
        patron = self._normalizar_patron(mensaje)
        
        query = """
        INSERT INTO respuestas_aprendidas 
        (patron_mensaje, intencion, contexto_previo, respuesta_generada, origen)
        VALUES (%s, %s, %s, %s, 'gpt')
        """
        
        try:
            self.db.ejecutar_query(
                query,
                (patron, intencion, contexto[:500], respuesta)
            )
            print(f"   ğŸ’¾ Respuesta guardada para aprendizaje")
        except Exception as e:
            print(f"   âš ï¸ Error guardando respuesta: {e}")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # FALLBACK
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _generar_fallback(self, mensaje: str, intencion: str) -> str:
        """Generar respuesta fallback cuando todo falla"""
        
        fallbacks = {
            'saludo': "Â¡Hola! Soy Kairos. Â¿En quÃ© puedo ayudarte?",
            'sintoma': "Entiendo. CuÃ©ntame mÃ¡s sobre eso.",
            'despedida': "Â¡CuÃ­date mucho! Hasta pronto.",
            'quien_eres': "Soy Kairos, tu mÃ©dico de cabecera virtual en el que puedes confiar.",
            'quien_te_creo': "Me creÃ³ Nilson Cayao, un joven apasionado por la tecnologÃ­a.",
            'producto': "Tenemos productos naturales como Moringa y Ganoderma. Â¿Sobre cuÃ¡l quieres saber?",
            'precio': "Los precios varÃ­an segÃºn el producto. Â¿CuÃ¡l te interesa?",
        }
        
        return fallbacks.get(intencion, "Â¿Puedes explicarme un poco mÃ¡s?")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # GESTIÃ“N DE APRENDIZAJE
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def calificar_respuesta(self, id_respuesta: int, calificacion: float):
        """
        Calificar una respuesta (1-5 estrellas)
        Actualiza el promedio
        """
        
        query = """
        UPDATE respuestas_aprendidas
        SET calificacion_promedio = (
            (calificacion_promedio * veces_usado + %s) / (veces_usado + 1)
        )
        WHERE id = %s
        """
        
        self.db.ejecutar_query(query, (calificacion, id_respuesta))
        print(f"   â­ Respuesta calificada: {calificacion}/5")
    
    def desactivar_respuesta(self, id_respuesta: int):
        """Desactivar una respuesta que no funcionÃ³ bien"""
        
        query = "UPDATE respuestas_aprendidas SET activo = FALSE WHERE id = %s"
        self.db.ejecutar_query(query, (id_respuesta,))
        print(f"   ğŸš« Respuesta {id_respuesta} desactivada")
    
    def obtener_estadisticas(self) -> Dict:
        """Obtener estadÃ­sticas del sistema de aprendizaje"""
        
        query = """
        SELECT 
            COUNT(*) as total_respuestas,
            SUM(veces_usado) as total_usos,
            AVG(calificacion_promedio) as calificacion_promedio,
            COUNT(DISTINCT intencion) as intenciones_aprendidas
        FROM respuestas_aprendidas
        WHERE activo = TRUE
        """
        
        resultado = self.db.ejecutar_query(query)
        
        if resultado:
            return {
                'respuestas_aprendidas': resultado[0]['total_respuestas'] or 0,
                'total_usos': resultado[0]['total_usos'] or 0,
                'calificacion_promedio': float(resultado[0]['calificacion_promedio'] or 0),
                'intenciones': resultado[0]['intenciones_aprendidas'] or 0
            }
        
        return {
            'respuestas_aprendidas': 0,
            'total_usos': 0,
            'calificacion_promedio': 0,
            'intenciones': 0
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# TESTS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    print("="*70)
    print("ğŸ§ª TEST RESPONSE GENERATOR")
    print("="*70)
    
    generator = ResponseGenerator()
    
    # Test generaciÃ³n
    print("\nğŸ“ TEST GENERACIÃ“N:\n")
    
    resultado = generator.generar_respuesta(
        mensaje="me duele la cabeza",
        intencion="sintoma",
        contexto="Paciente: Juan\nSÃ­ntoma principal: dolor de cabeza",
        system_prompt="Eres un mÃ©dico empÃ¡tico",
        usar_aprendizaje=True
    )
    
    print(f"Respuesta: {resultado['respuesta']}")
    print(f"Origen: {resultado['origen']}")
    print(f"Confianza: {resultado['confianza']:.0%}")
    
    # EstadÃ­sticas
    print("\nğŸ“Š ESTADÃSTICAS:")
    stats = generator.obtener_estadisticas()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\n" + "="*70)